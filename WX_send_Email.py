import os
import time
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from Bio import Entrez
from bs4 import BeautifulSoup
import requests
import logging
import dotenv
import json
from datetime import datetime, timedelta
import openai
import google.generativeai as genai
import argparse  # å¯¼å…¥ argparse
import hashlib

# Load environment variables from .env file
dotenv.load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ç¯å¢ƒå˜é‡é…ç½®
PUBMED_API_KEY = os.getenv("PUBMED_API_KEY")
EMAIL_ADDRESS = os.getenv("EMAIL_ADDRESS")
EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")
SMTP_SERVER = os.getenv("EMAIL_SMTP_SERVER", "smtp.yeah.net")
SMTP_PORT = int(os.getenv("EMAIL_SMTP_PORT", 465))
SEARCH_QUERY = os.getenv("SEARCH_QUERY")
MAX_RESULTS = int(os.getenv("MAX_RESULTS", 15))
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DEEPSEEK_BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
SUMMARY_LANGUAGE = os.getenv("SUMMARY_LANGUAGE", "en")

# åˆå§‹åŒ–é…ç½®
Entrez.email = EMAIL_ADDRESS
Entrez.api_key = PUBMED_API_KEY

# åˆå§‹åŒ– DeepSeek API å®¢æˆ·ç«¯
client = openai.OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)

# åˆå§‹åŒ– Gemini API å®¢æˆ·ç«¯
genai.configure(api_key=GEMINI_API_KEY)
gemini_model = genai.GenerativeModel('gemini-pro')

def generate_article_hash(article):
    """Generate a unique hash for an article based on its key information."""
    article_string = f"{article['title']}{article['abstract']}{article['authors']}{article['journal']}{article['year']}"
    return hashlib.md5(article_string.encode('utf-8')).hexdigest()


def load_processed_articles(filename="processed_articles.json"):
    """Load the list of already processed articles from a file."""
    try:
        with open(filename, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}
    except json.JSONDecodeError:
        logging.warning("âŒ processed_articles.json æ–‡ä»¶è§£ç å¤±è´¥ï¼Œä½¿ç”¨ç©ºå­—å…¸ã€‚")
        return {}


def save_processed_articles(processed_articles, filename="processed_articles.json"):
    """Save the list of processed articles to a file."""
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(processed_articles, f, ensure_ascii=False)


def fetch_articles():
    """è·å–æ–‡çŒ®åˆ—è¡¨å’ŒåŸºæœ¬ä¿¡æ¯"""
    try:
        handle = Entrez.esearch(
            db="pubmed",
            term=SEARCH_QUERY,
            retmax=MAX_RESULTS,
            sort="pub_date",
            usehistory="y"
        )
        result = Entrez.read(handle)
        id_list = result["IdList"]

        # Fetch article details in batch
        handle = Entrez.efetch(db="pubmed", id=",".join(id_list), rettype="xml", retmode="text")
        xml_data = handle.read()
        soup = BeautifulSoup(xml_data, "lxml-xml")

        articles = []
        for article in soup.find_all("PubmedArticle"):
            try:
                pmid = article.find("PMID").get_text()
                title = article.find("ArticleTitle").get_text() if article.find("ArticleTitle") else "æ— æ ‡é¢˜"
                journal = article.find("ISOAbbreviation").get_text() if article.find("ISOAbbreviation") else "æœªçŸ¥æ‚å¿—"
                year = article.find("Year").get_text() if article.find("Year") else "æœªçŸ¥å¹´ä»½"
                doi = article.find("ELocationID", {"EIdType": "doi"}).get_text() if article.find("ELocationID", {"EIdType": "doi"}) else "æ— DOI"
                pmcid = article.find("ArticleId", {"IdType": "pmc"}).get_text() if article.find("ArticleId", {"IdType": "pmc"}) else "æ— PMCID"

                # å¤„ç†ä½œè€…ä¿¡æ¯
                authors = []
                for author in article.find_all("Author"):
                    lastname = author.find("LastName").get_text() if author.find("LastName") else ""
                    initials = author.find("Initials").get_text() if author.find("Initials") else ""
                    if lastname and initials:
                        authors.append(f"{lastname} {initials}")

                # å¤„ç†æ‘˜è¦
                abstract = ""
                if abstract_section := article.find("Abstract"):
                    abstract = "\n".join([text.get_text() for text in abstract_section.find_all("AbstractText")])

                articles.append({
                    "pmid": pmid,
                    "title": title,
                    "journal": journal,
                    "year": year,
                    "doi": doi,
                    "pmcid": pmcid,
                    "authors": authors,
                    "abstract": abstract
                })
            except Exception as e:
                logging.error(f"è§£æPMID {pmid} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue  # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ç« 

        return articles

    except Exception as e:
        logging.error(f"æ–‡çŒ®æœç´¢å¤±è´¥: {str(e)}")
        return []


def get_fulltext_by_doi(doi):
    """å°è¯•é€šè¿‡DOIè·å–å…¨æ–‡"""
    if doi == "æ— DOI":
        return None

    try:
        url = f"https://doi.org/{doi}"
        response = requests.get(url, headers={"Accept": "text/plain"}, timeout=10)
        if response.status_code == 200:
            return response.text
        else:
            print(f"é€šè¿‡DOIè·å–å…¨æ–‡å¤±è´¥ (Status Code: {response.status_code}), doi: {doi}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"è¯·æ±‚DOIå…¨æ–‡å¤±è´¥: {str(e)}, doi: {doi}")
        return None


def get_fulltext_by_pmcid(pmcid):
    """å°è¯•é€šè¿‡PMCIDè·å–å…¨æ–‡"""
    if not pmcid or pmcid == "æ— PMCID":
        return None

    try:
        url = f"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{pmcid}/?format=txt"
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            return response.text
        else:
            print(f"é€šè¿‡PMCIDè·å–å…¨æ–‡å¤±è´¥ (Status Code: {response.status_code}), pmcid: {pmcid}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"è¯·æ±‚PMCIDå…¨æ–‡å¤±è´¥: {str(e)}, pmcid: {pmcid}")
        return None


def translate_text(text, target_language="zh-CN"):
    """ä½¿ç”¨ DeepSeek API ç¿»è¯‘æ–‡æœ¬, å¤±è´¥åˆ™ä½¿ç”¨ Gemini API"""
    if not text:
        return ""
    try:
        prompt = f"Translate the following text to {target_language}: {text}"
        response = client.chat.completions.create(
            model="deepseek-chat",  # æˆ–è€…é€‰æ‹©å…¶ä»–é€‚åˆç¿»è¯‘çš„æ¨¡å‹
            messages=[
                {"role": "system", "content": "You are a helpful assistant specialized in translating scientific articles."},
                {"role": "user", "content": prompt},
            ],
            stream=False
        )
        return response.choices[0].message.content.strip() if response.choices else text
    except Exception as e:
        logging.error(f"DeepSeek API ç¿»è¯‘å¤±è´¥: {str(e)}, å°è¯•ä½¿ç”¨ Gemini API")
        return translate_text_gemini(text, target_language)  # è°ƒç”¨ Gemini API


def summarize_text(text, target_language="en"):
    """ä½¿ç”¨ DeepSeek API ç”Ÿæˆæ–‡æœ¬æ€»ç»“, å¤±è´¥åˆ™ä½¿ç”¨ Gemini API"""
    if not text:
        return "æ— å†…å®¹å¯æ€»ç»“"
    try:
        prompt = f"""
        Please provide an academic summary of the following medical research article, 
        ensuring it encompasses the study's background, the methodology used, 
        the principal research results obtained, and an assessment of the research's significance and value. 
        The summary should be clear, concise, and free of unnecessary detail. 
        æ–‡æœ¬ï¼š
        {text}
        """
        response = client.chat.completions.create(
            model="deepseek-chat",  # æˆ–è€…é€‰æ‹©å…¶ä»–é€‚åˆæ‘˜è¦çš„æ¨¡å‹
            messages=[
                {"role": "system", "content": "You are a helpful assistant specialized in summarizing scientific articles."},
                {"role": "user", "content": prompt},
            ],
            stream=False
        )
        # æ¸…ç† DeepSeek API è¿”å›çš„æ–‡æœ¬
        summary = response.choices[0].message.content.strip() if response.choices else "æ— æ³•ç”Ÿæˆæ€»ç»“"
        cleaned_text = summary.replace("**", "").replace("*", "", ).replace("â– ", "").replace("â—", "").replace("â—†", "")
        return cleaned_text
    except Exception as e:
        logging.error(f"DeepSeek API æ€»ç»“å¤±è´¥: {str(e)}, å°è¯•ä½¿ç”¨ Gemini API")
        return summarize_text_gemini(text, target_language)  # è°ƒç”¨ Gemini API


def translate_text_gemini(text, target_language="zh-CN"):
    """ä½¿ç”¨ Gemini API ç¿»è¯‘æ–‡æœ¬"""
    if not text:
        return ""
    try:
        prompt = f"Translate the following text to {target_language}: {text}"
        response = gemini_model.generate_content(prompt)
        return response.text.strip() if response.text else text
    except Exception as e:
        logging.error(f"Gemini API ç¿»è¯‘å¤±è´¥: {str(e)}")
        return text


def summarize_text_gemini(text, target_language="en"):
    """ä½¿ç”¨ Gemini API ç”Ÿæˆæ–‡æœ¬æ€»ç»“"""
    if not text:
        return "æ— å†…å®¹å¯æ€»ç»“"
    try:
        prompt = f"""
        Please provide an academic summary of the following medical research article, 
        ensuring it encompasses the study's background, the methodology used, 
        the principal research results obtained, and an assessment of the research's significance and value. 
        The summary should be clear, concise, and free of unnecessary detail. 
        æ–‡æœ¬ï¼š
        {text}
        """
        response = gemini_model.generate_content(prompt)
        return response.text.strip() if response.text else "æ— æ³•ç”Ÿæˆæ€»ç»“"
    except Exception as e:
        logging.error(f"Gemini API æ€»ç»“å¤±è´¥: {str(e)}")
        return "æ— æ³•ç”Ÿæˆæ€»ç»“"


def send_email(articles):
    """å‘é€æ–‡çŒ®æ±‡æ€»é‚®ä»¶"""
    try:
        # æ„å»ºé‚®ä»¶å†…å®¹
        msg = MIMEMultipart()
        msg["From"] = EMAIL_ADDRESS
        msg["To"] = EMAIL_ADDRESS
        msg["Subject"] = f"PubMedæ–‡çŒ®æ›´æ–° - {SEARCH_QUERY}"

        # HTMLå†…å®¹æ¨¡æ¿
        html_content = f"""
        <html>
            <body>
                <h2>æœ€æ–° {len(articles)} ç¯‡æ–‡çŒ®</h2>
                <p>æœç´¢å…³é”®è¯: {SEARCH_QUERY}</p>
        """

        for idx, article in enumerate(articles, 1):
            html_content += f"""
            <div style="margin-bottom: 30px; border-bottom: 1px solid #eee;">
                <h3>{idx}. {article['title']}</h3>
                 <p><b>ä¸­æ–‡æ ‡é¢˜:</b> {article['translated_title']}</p>
                <p><b>ä½œè€…:</b> {', '.join(article['authors'])}</p>
                <p><b>æœŸåˆŠ:</b> {article['journal']} ({article['year']})</p>
                <p><b>ä¸­æ–‡æ€»ç»“:</b><br>{article['summary']}</p>
                <p>
                    <a href="{article['link']}">PubMedé“¾æ¥</a> |
                    <a href="https://doi.org/{article['doi']}">å…¨æ–‡é“¾æ¥</a>
                </p>
            </div>
            """

        html_content += "</body></html>"
        msg.attach(MIMEText(html_content, "html", "utf-8"))

        # å‘é€é‚®ä»¶
        try:
            logging.info(f"Connecting to SMTP server: {SMTP_SERVER}:{SMTP_PORT}")
            with smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT) as server:
                logging.info(f"Logging in to email account: {EMAIL_ADDRESS}")
                server.login(EMAIL_ADDRESS, EMAIL_PASSWORD)
                logging.info("Login successful.")
                logging.info(f"Sending email to: {EMAIL_ADDRESS}")
                server.send_message(msg)
                logging.info("âœ… é‚®ä»¶å‘é€æˆåŠŸ")
        except smtplib.SMTPException as e:
            logging.error(f"âŒ SMTP error occurred: {e}")
            raise  # Re-raise the exception to be caught in the outer block

    except Exception as e:
        logging.error(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {str(e)}")


def main(args):
    """ä¸»å‡½æ•°ï¼Œæ ¹æ®å‚æ•°æ‰§è¡Œä¸åŒçš„æ“ä½œã€‚"""
    logging.info("ğŸš€ å¼€å§‹æ‰§è¡Œ...")

    if args.fetch_and_summarize:
        logging.info("ğŸ”„ è·å–å¹¶æ€»ç»“æ–‡çŒ®...")
        all_articles = fetch_articles()

        if not all_articles:
            logging.warning("âŒ æœªæ‰¾åˆ°ç›¸å…³æ–‡çŒ®")
            return

        # Load previously processed articles
        processed_articles = load_processed_articles()

        new_articles = []
        for article in all_articles:
            # Generate hash for the article
            article_hash = generate_article_hash(article)

            # Check if the article has already been processed
            if article_hash not in processed_articles:
                # è·å–å…¨æ–‡
                fulltext = get_fulltext_by_doi(article["doi"])
                if not fulltext:
                    fulltext = get_fulltext_by_pmcid(article["pmcid"])

                # æ€»ç»“å’Œç¿»è¯‘
                if fulltext:
                    summary = summarize_text(fulltext)
                else:
                    summary = summarize_text(article["abstract"] or "æ— æ‘˜è¦")

                translated_summary = translate_text(summary, target_language="zh-CN")
                translated_title = translate_text(article["title"], target_language="zh-CN")

                # å°†ç»“æœæ·»åŠ åˆ° new_articles
                article["summary"] = translated_summary
                article["translated_title"] = translated_title
                article["link"] = f"https://pubmed.ncbi.nlm.nih.gov/{article['pmid']}/"
                new_articles.append(article)

                # Add article hash to the processed articles
                processed_articles[article_hash] = True  # You can store more information if needed

                logging.info(f"å·²æ·»åŠ æ–°æ–‡ç« : PMID {article['pmid']}, æ ‡é¢˜: {article['title']}")
                time.sleep(0.5)  # é¿å…é€Ÿç‡é™åˆ¶
            else:
                logging.info(f"æ–‡ç« å·²å­˜åœ¨: PMID {article['pmid']}, æ ‡é¢˜: {article['title']}")


        # Save the updated processed articles list
        save_processed_articles(processed_articles)


        # å°† new_articles ä¿å­˜åˆ°æ–‡ä»¶ï¼Œä¾› send æ­¥éª¤ä½¿ç”¨
        with open("new_articles.json", "w", encoding="utf-8") as f:
            json.dump(new_articles, f, ensure_ascii=False)  # é¿å… ASCII ç¼–ç é—®é¢˜

    elif args.send:
        logging.info("ğŸ“§ å‘é€é‚®ä»¶...")
        try:
            with open("new_articles.json", "r", encoding="utf-8") as f:
                new_articles = json.load(f)
        except FileNotFoundError:
            logging.warning("âŒ new_articles.json æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå¯èƒ½æ²¡æœ‰æ–°çš„æ–‡çŒ®éœ€è¦å‘é€ã€‚")
            return
        except json.JSONDecodeError:
            logging.error("âŒ new_articles.json æ–‡ä»¶è§£ç å¤±è´¥ï¼Œæ— æ³•å‘é€é‚®ä»¶ã€‚")
            return

        if new_articles:
            send_email(new_articles)  # åªå‘é€æ–°çš„æ–‡çŒ®
        else:
            logging.info("âŒ æ²¡æœ‰æ–°çš„æ–‡çŒ®éœ€è¦å‘é€")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Fetch and summarize PubMed articles and send email.")
    parser.add_argument("--fetch-and-summarize", action="store_true", help="Fetch and summarize articles.")
    parser.add_argument("--send", action="store_true", help="Send the email.")
    args = parser.parse_args()

    main(args)
